{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6cf6d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import preprocessing as pp\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow_model_optimization.sparsity import keras as sparsity\n",
    "import tensorflow_model_optimization as tfmot \n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d007bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/Users/donika/Desktop/images/metadata.csv')\n",
    "\n",
    "target_size = (128, 128)\n",
    "batch_size = 32\n",
    "\n",
    "train_folder_path = '/Users/donika/Desktop/images/datasets/train'\n",
    "val_folder_path = '/Users/donika/Desktop/images/datasets/validation'\n",
    "\n",
    "df_balanced = pp.balance_data(df)\n",
    "train_images, train_labels = pp.load_images_from_dataset(df_balanced, train_folder_path, target_size)\n",
    "print(\"Training samples after balancing:\", len(train_images))\n",
    "\n",
    "val_images, val_labels = pp.load_images_from_dataset(df, val_folder_path, target_size)\n",
    "print(\"Validation samples:\", len(val_images))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57e63668",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Labels Shape: (39502, 7)\n",
      "Validation Labels Shape: (500, 7)\n"
     ]
    }
   ],
   "source": [
    "encoder = OneHotEncoder()\n",
    "encoder.fit(train_labels.reshape(-1, 1))\n",
    "\n",
    "train_labels_encoded = encoder.transform(train_labels.reshape(-1, 1)).toarray()\n",
    "val_labels_encoded = encoder.transform(val_labels.reshape(-1, 1)).toarray()\n",
    "\n",
    "print(\"Train Labels Shape:\", train_labels_encoded.shape)\n",
    "print(\"Validation Labels Shape:\", val_labels_encoded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e43ce639",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " prune_low_magnitude_conv2d   (None, 126, 126, 32)     1762      \n",
      " (PruneLowMagnitude)                                             \n",
      "                                                                 \n",
      " prune_low_magnitude_max_poo  (None, 63, 63, 32)       1         \n",
      " ling2d (PruneLowMagnitude)                                      \n",
      "                                                                 \n",
      " prune_low_magnitude_batch_n  (None, 63, 63, 32)       129       \n",
      " ormalization (PruneLowMagni                                     \n",
      " tude)                                                           \n",
      "                                                                 \n",
      " prune_low_magnitude_conv2d_  (None, 61, 61, 64)       36930     \n",
      " 1 (PruneLowMagnitude)                                           \n",
      "                                                                 \n",
      " prune_low_magnitude_max_poo  (None, 30, 30, 64)       1         \n",
      " ling2d_1 (PruneLowMagnitude                                     \n",
      " )                                                               \n",
      "                                                                 \n",
      " prune_low_magnitude_batch_n  (None, 30, 30, 64)       257       \n",
      " ormalization_1 (PruneLowMag                                     \n",
      " nitude)                                                         \n",
      "                                                                 \n",
      " prune_low_magnitude_conv2d_  (None, 28, 28, 128)      147586    \n",
      " 2 (PruneLowMagnitude)                                           \n",
      "                                                                 \n",
      " prune_low_magnitude_max_poo  (None, 14, 14, 128)      1         \n",
      " ling2d_2 (PruneLowMagnitude                                     \n",
      " )                                                               \n",
      "                                                                 \n",
      " prune_low_magnitude_batch_n  (None, 14, 14, 128)      513       \n",
      " ormalization_2 (PruneLowMag                                     \n",
      " nitude)                                                         \n",
      "                                                                 \n",
      " prune_low_magnitude_flatten  (None, 25088)            1         \n",
      "  (PruneLowMagnitude)                                            \n",
      "                                                                 \n",
      " prune_low_magnitude_dense (  (None, 256)              12845314  \n",
      " PruneLowMagnitude)                                              \n",
      "                                                                 \n",
      " prune_low_magnitude_dropout  (None, 256)              1         \n",
      "  (PruneLowMagnitude)                                            \n",
      "                                                                 \n",
      " prune_low_magnitude_dense_1  (None, 128)              65666     \n",
      "  (PruneLowMagnitude)                                            \n",
      "                                                                 \n",
      " prune_low_magnitude_dropout  (None, 128)              1         \n",
      " _1 (PruneLowMagnitude)                                          \n",
      "                                                                 \n",
      " prune_low_magnitude_dense_2  (None, 7)                1801      \n",
      "  (PruneLowMagnitude)                                            \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13,099,964\n",
      "Trainable params: 6,550,279\n",
      "Non-trainable params: 6,549,685\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential([\n",
    "   \n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 3)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.BatchNormalization(),\n",
    "    \n",
    "    \n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.BatchNormalization(),\n",
    "    \n",
    "    \n",
    "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Flatten(),\n",
    "    \n",
    "    \n",
    "    layers.Dense(256, activation='relu'),\n",
    "    layers.Dropout(0.5),  \n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(7, activation='softmax') \n",
    "])\n",
    "\n",
    "\n",
    "epochs = 30\n",
    "batch_size = 32\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])\n",
    "\n",
    "pruned_model = sparsity.prune_low_magnitude(model, \n",
    "                                            **{'pruning_schedule': sparsity.PolynomialDecay(initial_sparsity=0.50, final_sparsity=0.90, begin_step=0, end_step=1000)})\n",
    "pruned_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])\n",
    "pruned_model.summary()\n",
    "\n",
    "\n",
    "\n",
    "update_pruning = tfmot.sparsity.keras.UpdatePruningStep()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d3759ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-28 06:54:05.823198: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1235/1235 [==============================] - 350s 281ms/step - loss: 2.2011 - accuracy: 0.3273 - precision_1: 0.5150 - recall_1: 0.1232 - val_loss: 1.0143 - val_accuracy: 0.6340 - val_precision_1: 0.8972 - val_recall_1: 0.3840\n",
      "Epoch 2/30\n",
      "1235/1235 [==============================] - 338s 273ms/step - loss: 1.2914 - accuracy: 0.4788 - precision_1: 0.8164 - recall_1: 0.2375 - val_loss: 0.9496 - val_accuracy: 0.5560 - val_precision_1: 0.8099 - val_recall_1: 0.3920\n",
      "Epoch 3/30\n",
      "1235/1235 [==============================] - 363s 294ms/step - loss: 1.0250 - accuracy: 0.5896 - precision_1: 0.8353 - recall_1: 0.3724 - val_loss: 0.8590 - val_accuracy: 0.6040 - val_precision_1: 0.8415 - val_recall_1: 0.4780\n",
      "Epoch 4/30\n",
      "1235/1235 [==============================] - 482s 390ms/step - loss: 0.8313 - accuracy: 0.6711 - precision_1: 0.8490 - recall_1: 0.4876 - val_loss: 1.0323 - val_accuracy: 0.5940 - val_precision_1: 0.7194 - val_recall_1: 0.4460\n",
      "Epoch 5/30\n",
      "1235/1235 [==============================] - 516s 418ms/step - loss: 0.6759 - accuracy: 0.7387 - precision_1: 0.8545 - recall_1: 0.6106 - val_loss: 1.1097 - val_accuracy: 0.5920 - val_precision_1: 0.6546 - val_recall_1: 0.5080\n",
      "Epoch 6/30\n",
      "1235/1235 [==============================] - 508s 411ms/step - loss: 0.5702 - accuracy: 0.7804 - precision_1: 0.8620 - recall_1: 0.6902 - val_loss: 1.4373 - val_accuracy: 0.6160 - val_precision_1: 0.6502 - val_recall_1: 0.5540\n",
      "Epoch 7/30\n",
      "1235/1235 [==============================] - 485s 393ms/step - loss: 0.4955 - accuracy: 0.8068 - precision_1: 0.8680 - recall_1: 0.7445 - val_loss: 1.1739 - val_accuracy: 0.6520 - val_precision_1: 0.6890 - val_recall_1: 0.6160\n",
      "Epoch 8/30\n",
      "1235/1235 [==============================] - 482s 390ms/step - loss: 0.4344 - accuracy: 0.8308 - precision_1: 0.8765 - recall_1: 0.7810 - val_loss: 1.2525 - val_accuracy: 0.6600 - val_precision_1: 0.6802 - val_recall_1: 0.6040\n",
      "Epoch 9/30\n",
      "1235/1235 [==============================] - 527s 427ms/step - loss: 0.3874 - accuracy: 0.8479 - precision_1: 0.8870 - recall_1: 0.8081 - val_loss: 4.6136 - val_accuracy: 0.5000 - val_precision_1: 0.5173 - val_recall_1: 0.4780\n",
      "Epoch 10/30\n",
      "1235/1235 [==============================] - 544s 440ms/step - loss: 0.3556 - accuracy: 0.8622 - precision_1: 0.8953 - recall_1: 0.8288 - val_loss: 1.3849 - val_accuracy: 0.6860 - val_precision_1: 0.7124 - val_recall_1: 0.6340\n",
      "Epoch 11/30\n",
      "1235/1235 [==============================] - 573s 464ms/step - loss: 0.3234 - accuracy: 0.8738 - precision_1: 0.9008 - recall_1: 0.8466 - val_loss: 1.5495 - val_accuracy: 0.6540 - val_precision_1: 0.6681 - val_recall_1: 0.6160\n",
      "Epoch 12/30\n",
      "1235/1235 [==============================] - 571s 462ms/step - loss: 0.2970 - accuracy: 0.8829 - precision_1: 0.9082 - recall_1: 0.8579 - val_loss: 1.6101 - val_accuracy: 0.6940 - val_precision_1: 0.7053 - val_recall_1: 0.6700\n",
      "Epoch 13/30\n",
      "1235/1235 [==============================] - 574s 465ms/step - loss: 0.2844 - accuracy: 0.8896 - precision_1: 0.9123 - recall_1: 0.8667 - val_loss: 1.4424 - val_accuracy: 0.7460 - val_precision_1: 0.7552 - val_recall_1: 0.7280\n",
      "Epoch 14/30\n",
      "1235/1235 [==============================] - 564s 457ms/step - loss: 0.2553 - accuracy: 0.9007 - precision_1: 0.9190 - recall_1: 0.8825 - val_loss: 2.0120 - val_accuracy: 0.7200 - val_precision_1: 0.7258 - val_recall_1: 0.7040\n",
      "Epoch 15/30\n",
      "1235/1235 [==============================] - 553s 448ms/step - loss: 0.2417 - accuracy: 0.9038 - precision_1: 0.9201 - recall_1: 0.8891 - val_loss: 2.4938 - val_accuracy: 0.6280 - val_precision_1: 0.6429 - val_recall_1: 0.6120\n",
      "Epoch 16/30\n",
      "1235/1235 [==============================] - 591s 479ms/step - loss: 0.2360 - accuracy: 0.9078 - precision_1: 0.9240 - recall_1: 0.8920 - val_loss: 3.2140 - val_accuracy: 0.6040 - val_precision_1: 0.6176 - val_recall_1: 0.5880\n",
      "Epoch 17/30\n",
      "1235/1235 [==============================] - 534s 433ms/step - loss: 0.2116 - accuracy: 0.9173 - precision_1: 0.9306 - recall_1: 0.9058 - val_loss: 1.8921 - val_accuracy: 0.6960 - val_precision_1: 0.7050 - val_recall_1: 0.6740\n",
      "Epoch 18/30\n",
      "1235/1235 [==============================] - 547s 443ms/step - loss: 0.2019 - accuracy: 0.9225 - precision_1: 0.9341 - recall_1: 0.9120 - val_loss: 1.8701 - val_accuracy: 0.6620 - val_precision_1: 0.6680 - val_recall_1: 0.6440\n",
      "Epoch 19/30\n",
      "1235/1235 [==============================] - 507s 411ms/step - loss: 0.1928 - accuracy: 0.9257 - precision_1: 0.9368 - recall_1: 0.9155 - val_loss: 2.7635 - val_accuracy: 0.7200 - val_precision_1: 0.7267 - val_recall_1: 0.7180\n",
      "Epoch 20/30\n",
      "1235/1235 [==============================] - 459s 372ms/step - loss: 0.1814 - accuracy: 0.9289 - precision_1: 0.9385 - recall_1: 0.9196 - val_loss: 2.1717 - val_accuracy: 0.6900 - val_precision_1: 0.7037 - val_recall_1: 0.6840\n",
      "Epoch 21/30\n",
      "1235/1235 [==============================] - 452s 366ms/step - loss: 0.1847 - accuracy: 0.9300 - precision_1: 0.9385 - recall_1: 0.9206 - val_loss: 2.9143 - val_accuracy: 0.6000 - val_precision_1: 0.5992 - val_recall_1: 0.5740\n",
      "Epoch 22/30\n",
      "1235/1235 [==============================] - 458s 371ms/step - loss: 0.1718 - accuracy: 0.9349 - precision_1: 0.9428 - recall_1: 0.9264 - val_loss: 2.0996 - val_accuracy: 0.6980 - val_precision_1: 0.7029 - val_recall_1: 0.6860\n",
      "Epoch 23/30\n",
      "1235/1235 [==============================] - 454s 368ms/step - loss: 0.1590 - accuracy: 0.9391 - precision_1: 0.9467 - recall_1: 0.9322 - val_loss: 2.4796 - val_accuracy: 0.7360 - val_precision_1: 0.7429 - val_recall_1: 0.7340\n",
      "Epoch 24/30\n",
      "1235/1235 [==============================] - 464s 376ms/step - loss: 0.1562 - accuracy: 0.9391 - precision_1: 0.9463 - recall_1: 0.9318 - val_loss: 2.4476 - val_accuracy: 0.7220 - val_precision_1: 0.7258 - val_recall_1: 0.7200\n",
      "Epoch 25/30\n",
      "1235/1235 [==============================] - 461s 373ms/step - loss: 0.1549 - accuracy: 0.9391 - precision_1: 0.9467 - recall_1: 0.9331 - val_loss: 2.9216 - val_accuracy: 0.7400 - val_precision_1: 0.7429 - val_recall_1: 0.7340\n",
      "Epoch 26/30\n",
      "1235/1235 [==============================] - 456s 370ms/step - loss: 0.1488 - accuracy: 0.9433 - precision_1: 0.9497 - recall_1: 0.9372 - val_loss: 2.0669 - val_accuracy: 0.7440 - val_precision_1: 0.7495 - val_recall_1: 0.7360\n",
      "Epoch 27/30\n",
      "1235/1235 [==============================] - 463s 375ms/step - loss: 0.1399 - accuracy: 0.9462 - precision_1: 0.9511 - recall_1: 0.9405 - val_loss: 2.1463 - val_accuracy: 0.7280 - val_precision_1: 0.7286 - val_recall_1: 0.7140\n",
      "Epoch 28/30\n",
      "1235/1235 [==============================] - 449s 363ms/step - loss: 0.1386 - accuracy: 0.9486 - precision_1: 0.9536 - recall_1: 0.9439 - val_loss: 3.4694 - val_accuracy: 0.6400 - val_precision_1: 0.6414 - val_recall_1: 0.6260\n",
      "Epoch 29/30\n",
      "1235/1235 [==============================] - 444s 359ms/step - loss: 0.1350 - accuracy: 0.9490 - precision_1: 0.9549 - recall_1: 0.9443 - val_loss: 2.3150 - val_accuracy: 0.7480 - val_precision_1: 0.7556 - val_recall_1: 0.7480\n",
      "Epoch 30/30\n",
      "1235/1235 [==============================] - 451s 365ms/step - loss: 0.1386 - accuracy: 0.9485 - precision_1: 0.9532 - recall_1: 0.9442 - val_loss: 2.7374 - val_accuracy: 0.7360 - val_precision_1: 0.7429 - val_recall_1: 0.7340\n"
     ]
    }
   ],
   "source": [
    "history=pruned_model.fit(train_images, train_labels_encoded, epochs=epochs, batch_size=batch_size,\n",
    "                 validation_data=(val_images, val_labels_encoded), callbacks=[update_pruning])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ddf5ee2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [2.2011165618896484,\n",
       "  1.2914139032363892,\n",
       "  1.025023102760315,\n",
       "  0.8313309550285339,\n",
       "  0.6759310960769653,\n",
       "  0.5702213048934937,\n",
       "  0.4954562187194824,\n",
       "  0.4344058632850647,\n",
       "  0.387387216091156,\n",
       "  0.3556223511695862,\n",
       "  0.3233681917190552,\n",
       "  0.2969955801963806,\n",
       "  0.28444159030914307,\n",
       "  0.25532758235931396,\n",
       "  0.24166898429393768,\n",
       "  0.23600150644779205,\n",
       "  0.21160954236984253,\n",
       "  0.20186296105384827,\n",
       "  0.19277967512607574,\n",
       "  0.18140985071659088,\n",
       "  0.1846720278263092,\n",
       "  0.17180484533309937,\n",
       "  0.15899640321731567,\n",
       "  0.15616539120674133,\n",
       "  0.15486106276512146,\n",
       "  0.14881940186023712,\n",
       "  0.1398506909608841,\n",
       "  0.13859356939792633,\n",
       "  0.13495497405529022,\n",
       "  0.13855858147144318],\n",
       " 'accuracy': [0.3272745609283447,\n",
       "  0.4787858724594116,\n",
       "  0.5895904302597046,\n",
       "  0.6711052656173706,\n",
       "  0.7386967539787292,\n",
       "  0.7804161906242371,\n",
       "  0.8067692518234253,\n",
       "  0.8307680487632751,\n",
       "  0.8479064106941223,\n",
       "  0.8621841669082642,\n",
       "  0.8737785220146179,\n",
       "  0.8829426169395447,\n",
       "  0.8896258473396301,\n",
       "  0.9006885886192322,\n",
       "  0.9038023352622986,\n",
       "  0.9077515006065369,\n",
       "  0.9173459410667419,\n",
       "  0.9225102663040161,\n",
       "  0.9257252812385559,\n",
       "  0.9288643598556519,\n",
       "  0.9300288558006287,\n",
       "  0.9348640441894531,\n",
       "  0.9391170144081116,\n",
       "  0.9391170144081116,\n",
       "  0.939091682434082,\n",
       "  0.9432939887046814,\n",
       "  0.9461546540260315,\n",
       "  0.948559582233429,\n",
       "  0.9489899277687073,\n",
       "  0.9484836459159851],\n",
       " 'precision_1': [0.5150264501571655,\n",
       "  0.8164331316947937,\n",
       "  0.8353208303451538,\n",
       "  0.848950982093811,\n",
       "  0.8544906973838806,\n",
       "  0.8620209693908691,\n",
       "  0.8679907917976379,\n",
       "  0.8765449523925781,\n",
       "  0.8869654536247253,\n",
       "  0.8953370451927185,\n",
       "  0.9008431434631348,\n",
       "  0.9081627130508423,\n",
       "  0.9122788310050964,\n",
       "  0.9190108180046082,\n",
       "  0.9201425313949585,\n",
       "  0.9240493178367615,\n",
       "  0.9306057691574097,\n",
       "  0.9340679049491882,\n",
       "  0.9368216395378113,\n",
       "  0.9385366439819336,\n",
       "  0.938453197479248,\n",
       "  0.9428299069404602,\n",
       "  0.9467067718505859,\n",
       "  0.9463156461715698,\n",
       "  0.9466789960861206,\n",
       "  0.9497434496879578,\n",
       "  0.9510559439659119,\n",
       "  0.9535573720932007,\n",
       "  0.9548945426940918,\n",
       "  0.953157365322113],\n",
       " 'recall_1': [0.12320895493030548,\n",
       "  0.2374563366174698,\n",
       "  0.37238621711730957,\n",
       "  0.4875955581665039,\n",
       "  0.6105513572692871,\n",
       "  0.6901928782463074,\n",
       "  0.7445445656776428,\n",
       "  0.7809731364250183,\n",
       "  0.8080856800079346,\n",
       "  0.8287681341171265,\n",
       "  0.8465900421142578,\n",
       "  0.857905924320221,\n",
       "  0.8666902780532837,\n",
       "  0.882461667060852,\n",
       "  0.8890689015388489,\n",
       "  0.8919548392295837,\n",
       "  0.9057515859603882,\n",
       "  0.9120297431945801,\n",
       "  0.91554856300354,\n",
       "  0.9196243286132812,\n",
       "  0.9206116199493408,\n",
       "  0.9264087677001953,\n",
       "  0.9322313070297241,\n",
       "  0.9317502975463867,\n",
       "  0.9330666661262512,\n",
       "  0.9371930360794067,\n",
       "  0.9405346512794495,\n",
       "  0.9439015984535217,\n",
       "  0.9443066120147705,\n",
       "  0.9442053437232971],\n",
       " 'val_loss': [1.0142699480056763,\n",
       "  0.9496235251426697,\n",
       "  0.8590142726898193,\n",
       "  1.0322591066360474,\n",
       "  1.1096937656402588,\n",
       "  1.4373472929000854,\n",
       "  1.1739368438720703,\n",
       "  1.2525051832199097,\n",
       "  4.61355447769165,\n",
       "  1.384909749031067,\n",
       "  1.5495367050170898,\n",
       "  1.610140323638916,\n",
       "  1.4424189329147339,\n",
       "  2.012006998062134,\n",
       "  2.4938223361968994,\n",
       "  3.2140371799468994,\n",
       "  1.892082929611206,\n",
       "  1.8700543642044067,\n",
       "  2.7635231018066406,\n",
       "  2.1717007160186768,\n",
       "  2.9142935276031494,\n",
       "  2.0995571613311768,\n",
       "  2.4795844554901123,\n",
       "  2.4475979804992676,\n",
       "  2.92159366607666,\n",
       "  2.066920518875122,\n",
       "  2.146315813064575,\n",
       "  3.4694175720214844,\n",
       "  2.3150196075439453,\n",
       "  2.737361192703247],\n",
       " 'val_accuracy': [0.6340000033378601,\n",
       "  0.5559999942779541,\n",
       "  0.6039999723434448,\n",
       "  0.593999981880188,\n",
       "  0.5920000076293945,\n",
       "  0.6159999966621399,\n",
       "  0.6520000100135803,\n",
       "  0.6600000262260437,\n",
       "  0.5,\n",
       "  0.6859999895095825,\n",
       "  0.6539999842643738,\n",
       "  0.6940000057220459,\n",
       "  0.7459999918937683,\n",
       "  0.7200000286102295,\n",
       "  0.628000020980835,\n",
       "  0.6039999723434448,\n",
       "  0.6959999799728394,\n",
       "  0.6620000004768372,\n",
       "  0.7200000286102295,\n",
       "  0.6899999976158142,\n",
       "  0.6000000238418579,\n",
       "  0.6980000138282776,\n",
       "  0.7360000014305115,\n",
       "  0.722000002861023,\n",
       "  0.7400000095367432,\n",
       "  0.7440000176429749,\n",
       "  0.7279999852180481,\n",
       "  0.6399999856948853,\n",
       "  0.7480000257492065,\n",
       "  0.7360000014305115],\n",
       " 'val_precision_1': [0.8971962332725525,\n",
       "  0.8099173307418823,\n",
       "  0.841549277305603,\n",
       "  0.7193548679351807,\n",
       "  0.6546391844749451,\n",
       "  0.6502347588539124,\n",
       "  0.6890380382537842,\n",
       "  0.6801801919937134,\n",
       "  0.5173160433769226,\n",
       "  0.7123595476150513,\n",
       "  0.6681128144264221,\n",
       "  0.7052631378173828,\n",
       "  0.7551867365837097,\n",
       "  0.7257732152938843,\n",
       "  0.6428571343421936,\n",
       "  0.6176470518112183,\n",
       "  0.7050209045410156,\n",
       "  0.6680498123168945,\n",
       "  0.7267206311225891,\n",
       "  0.7037037014961243,\n",
       "  0.5991649031639099,\n",
       "  0.7028688788414001,\n",
       "  0.7429149746894836,\n",
       "  0.725806474685669,\n",
       "  0.7429149746894836,\n",
       "  0.7494908571243286,\n",
       "  0.7285714149475098,\n",
       "  0.6413934230804443,\n",
       "  0.7555555701255798,\n",
       "  0.7429149746894836],\n",
       " 'val_recall_1': [0.3840000033378601,\n",
       "  0.3919999897480011,\n",
       "  0.4779999852180481,\n",
       "  0.44600000977516174,\n",
       "  0.5080000162124634,\n",
       "  0.5540000200271606,\n",
       "  0.6159999966621399,\n",
       "  0.6039999723434448,\n",
       "  0.4779999852180481,\n",
       "  0.6340000033378601,\n",
       "  0.6159999966621399,\n",
       "  0.6700000166893005,\n",
       "  0.7279999852180481,\n",
       "  0.7039999961853027,\n",
       "  0.6119999885559082,\n",
       "  0.5879999995231628,\n",
       "  0.6740000247955322,\n",
       "  0.6439999938011169,\n",
       "  0.7179999947547913,\n",
       "  0.6840000152587891,\n",
       "  0.5740000009536743,\n",
       "  0.6859999895095825,\n",
       "  0.734000027179718,\n",
       "  0.7200000286102295,\n",
       "  0.734000027179718,\n",
       "  0.7360000014305115,\n",
       "  0.7139999866485596,\n",
       "  0.6259999871253967,\n",
       "  0.7480000257492065,\n",
       "  0.734000027179718]}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6db08234",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 2s 105ms/step\n",
      "Confusion Matrix:\n",
      " [[ 26   6   0   8   0   2   4]\n",
      " [ 12 301   0  29   0   4   1]\n",
      " [  3   0   1   1   0   1   2]\n",
      " [ 10   9   1  25   0   0   3]\n",
      " [  1   4   0   1   5   0   0]\n",
      " [  3   4   1   0   0   6  10]\n",
      " [  6   5   0   1   0   0   4]]\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(val_images)\n",
    "pred_labels = np.argmax(predictions, axis=1)\n",
    "\n",
    "true_labels = np.argmax(val_labels_encoded, axis=1)\n",
    "confusion_matrix = tf.math.confusion_matrix(true_labels, pred_labels)\n",
    "\n",
    "print('Confusion Matrix:\\n', confusion_matrix.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "26137681",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 2s 108ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.57      0.49        46\n",
      "           1       0.91      0.87      0.89       347\n",
      "           2       0.33      0.12      0.18         8\n",
      "           3       0.38      0.52      0.44        48\n",
      "           4       1.00      0.45      0.62        11\n",
      "           5       0.46      0.25      0.32        24\n",
      "           6       0.17      0.25      0.20        16\n",
      "\n",
      "    accuracy                           0.74       500\n",
      "   macro avg       0.53      0.43      0.45       500\n",
      "weighted avg       0.77      0.74      0.74       500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(val_images)\n",
    "pred_labels = np.argmax(predictions, axis=1)\n",
    "\n",
    "true_labels = np.argmax(val_labels_encoded, axis=1)\n",
    "report = classification_report(true_labels, pred_labels)\n",
    "\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92035ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('/Users/donika/Desktop/images/model_training/model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f19b4222",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6f3f35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a04321",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
